{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process job words and store their frequencies as dictionary\n",
    "# job title visualization using wordcloud\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "file_name = 'hidden'\n",
    "data = pd.read_csv(file_name, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_string = \"\"\n",
    "whole_word_list = []\n",
    "cnt = 0\n",
    "\n",
    "def extract_titles (title):\n",
    "    global title_string, whole_word_list\n",
    "    if title and title == title:\n",
    "        title_string = title_string + title.lower() + \" \"\n",
    "    global cnt; cnt = cnt + 1\n",
    "    if cnt % 10000 == 0:\n",
    "        # print(cnt)\n",
    "        whole_word_list = whole_word_list + word_tokenize(title_string)\n",
    "        title_string = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'].apply(extract_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
    "re_list = retokenize.tokenize(title_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = set([x for x in whole_word_list if x not in re_list])   # temp_list - word_list\n",
    "\n",
    "real_symbol_list = []\n",
    "for word in symbol_list:\n",
    "    if len(word) == 1:\n",
    "        real_symbol_list.append(word)\n",
    "\n",
    "print(real_symbol_list)\n",
    "\n",
    "# real_symbol_list = ['\\x96', '{', '‚úî', '‚Äû', '‚Çø', 'üçÉ', 'k', '¬Æ', '–∏', '0', '¬´', ';', '‚àô', '‚Äú', 'f', '‚Äê', '‚û£', '^', '‚òÖ', '‚û¢', ',', '6', '\\u200b', '#', '/', '‚Äô', '\\u200d', '‚Äî', '‚ôõ', '7', 'ü§´', '√†', '}', '@', '¬∑', '<', '√°', 'u', '?', '‚àû', \"'\", '‚ô¶', '‚ûü', 'g', '¬ª', '8', '!', '‚Ä¢', '‚Ñ¢', '1', '3', '‚àí', '\\uf8ff', '%', 'z', ':', '*', '[', '‚áâ', '4', '\\u202c', 'ü•∑', '=', '‚áí', 'h', '+', '(', '‚óè', '‚Üî', '\\\\', '\\u200e', '◊®', 'üîé', '‚û≤', '&', '‚ñ∫', 'i', '‚Äù', '–≤', '‚Äò', '¬ß', '‚óÜ', 'y', '‚óä', '>', '‚îÇ', ']', '9', '~', 'j', 'b', 'n', '‚ú¶', '|', 'o', ')', 'ÔºÜ', 'l', '.', '¬¶', '`', '$', '‚Äì', 'Œπ', '-', '‚ì¶', 'w', '\\x03', 'q', '\\xad', '5', '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "word_list = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for word in whole_word_list:\n",
    "    if word not in stop_words and word not in real_symbol_list:\n",
    "        word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "word_count = dict(collections.Counter(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cloud = WordCloud(width=1600, height=900, background_color=\"white\", random_state=0)\n",
    "plt.imshow(cloud.generate_from_frequencies(word_count))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "cloud.to_file('wordcloud_title_whole.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "\n",
    "with open('data_dict.pkl','wb') as f:\n",
    "    pickle.dump(sorted(word_count.items(), key=operator.itemgetter(1), reverse=True), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(word_count.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77802085aab8c37bdce3409d9441b84fc57e6168b0d9abbdab72f1c43fb36842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
