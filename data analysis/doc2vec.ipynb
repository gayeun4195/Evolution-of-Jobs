{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply doc2vec (using title, description columns)\n",
    "# tried to cluster job titles\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = 'hidden'\n",
    "data = pd.read_csv(file_name, low_memory = False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "\n",
    "def extract_titles (row):\n",
    "    global documents\n",
    "    if row['description'] and row['description'] == row['description']:\n",
    "        documents[row['title']] = text_to_word_sequence(row['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(extract_titles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from title_analysis_keras.ipynb\n",
    "real_symbol_list = ['≈ü', '8', '‚Çø', '‚Ä¢', '¬∑', 'z', '\\xad', '5', 'r', 'p', 'o', 'n', '‚óÜ', '‚ñ∫', 'üîé', 'g', '1', '4', '6', '9', 'y', '‚óè', '‚àû', '\\xa0', 'f', \"'\", 'u', '◊®', '0', '‚áâ', '‚àí', 'm', '\\u200e', '√†', '¬ª', 'ü§´', 'ÔºÜ', '¬¶', 'k', 'b', '\\x96', 'l', 'i', '‚ûü', '‚ú¶', 't', '‚û¢', '7', '¬ß', '–≤', '‚Äê', '‚û≤', 'j', '‚òÖ', '\\u202c', 'd', '\\u200b', 'c', 'e', '‚óä', '‚Äî', '¬´', 'w', '‚àô', '\\x03', 'v', 'Œπ', '‚Üî', '‚ôõ', '‚áí', '‚ô¶', '3', '‚û£', '‚Ñ¢', '‚îÇ', '–∏', '‚Äì', 'h', 'q']\n",
    "\n",
    "from os import remove\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "word_list = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for key, description in documents.items():\n",
    "    new_description = []\n",
    "    for word in description:\n",
    "        if word not in stop_words and word not in real_symbol_list:\n",
    "            new_description.append(word)\n",
    "        documents[key] = new_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for title, description in documents.items():\n",
    "    titles.append(title)\n",
    "\n",
    "indexed_titles = []\n",
    "for i in range(len(titles)):\n",
    "    new_title = str(i) + \"_\" + titles[i]\n",
    "    indexed_titles.append(new_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [TaggedDocument(words = documents[titles[i]], tags = titles[i]) for i in range(len(titles))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size = 10, window = 3, epochs = 40, min_count = 1)\n",
    "model.build_vocab(train)\n",
    "model.train(train, total_examples=len(train), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferreds = []\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    inferred = model.infer_vector(documents[titles[i]])\n",
    "    inferreds.append(inferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inertia = []\n",
    "for i in range(1, 11):\n",
    "    model = KMeans(n_clusters=i)\n",
    "    model.fit(inferreds)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), inertia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "clustering = KMeans(n_clusters=n)\n",
    "clustering.fit(inferreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {i:[] for i in range(0, n)}\n",
    "for i in range(len(titles)):\n",
    "    cluster_dict[clustering.labels_[i]].append(titles[i])\n",
    "\n",
    "cluster_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77802085aab8c37bdce3409d9441b84fc57e6168b0d9abbdab72f1c43fb36842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
